---
permalink: /
title: ""
excerpt: "FAQ about AI@UW"
author_profile: true
redirect_from: 
  - /ai-faq/
  - /ai-faq.html
---

## Frequently Asked Questions About AI at UW

In November 2025, I took on the role of Vice Provost of Artificial Intelligence at the University of Washington.  Since then, many questions have come up.  I've attempted to address some of them here.

### Are you forcing "AI" (usually used to refer to language models) into UW classrooms?

No. We are **not** forcing language models or other technologies into anyone’s teaching. **Faculty autonomy in pedagogy is sacrosanct.** What we *are* doing is offering support so instructors can make informed choices that fit their learning goals, and can clearly explain the reasoning behind those choices to students.  If we protect faculty autonomy, and faculty make different choices, then we owe it to the students to explain how we reach different conclusions about how language models should be used in our classrooms.  

### Some students have negative sentiment toward language models and do not want AI to intrude in education.  Are you ignoring that?

Not at all. Student concerns are real and worth engaging. The goal is not to "sell" LMs or require their use; it’s to empower faculty and students to navigate a changed landscape thoughtfully. That includes helping instructors communicate clear expectations and reasoning to students, whatever they decide.  It also includes enabling everyone to learn what approaches are effective for learning, and encouraging creative thinking that will shape what "AI" looks like in the future (rather than just reacting to the current state of the technology).  

### As educators, shouldn’t we prioritize and protect students who reject AI on principled grounds?

We should take those positions seriously and create learning environments where students can succeed, without coercing them to act against their principles.  At the same time, the tools we call AI are likely to show up in our students' careers and lives, and those who avoid the tools altogether may be sacrificing opportunities.  We owe students something more than a simple “opt out”: we should help them develop the capacity to **reason well about the tradeoffs**, understand what these systems are (and aren’t), and participate in constructive debate about responsible use. Supporting students doesn’t mean avoiding hard conversations; it means having them respectfully, with evidence and nuance.

I'd add, too, that we can't ignore students who believe that being prepared for life after university requires learning to work *with* AI.  In my field of computer science, it's becoming clear that those able to effectively use AI to help with complex coding projects will be far more capable than those who are not.  (For many years I didn't write code at all, because I was too busy to keep up with the latest tools.  With the help of an AI assistant, I am now writing code to solve problems that would I would have had to delegate to others just a few months ago.)

### What about misuse?

Misuse happens, and it can undermine learning. But “some students will misuse tools” is not new; what’s new is the scale and accessibility of the tools. That’s exactly why we’re focusing on **informed instructional choices** and **best practices**: what kinds of assignments are resilient, what guidance helps students learn, and what approaches are effective (or ineffective) if an instructor chooses to incorporate AI in some way.

### There is concern about environmental harm from AI and data centers. Is opting out the most ethical response?

Environmental impact is a serious concern, and I share it. In my research, I've worked on "[Green AI](https://cacm.acm.org/research/green-ai/)" questions and believe we need **better measurement, transparency, and mitigation**.  I'm proud that our [OLMo efforts](https://arxiv.org/pdf/2501.00656) have been among the most transparent in reporting the impacts of building language models.  The landscape is also evolving quickly, both in how impacts are measured and how systems are built and operated.

Opting out is *one* response, and for some people it may be the right one. But everyone ought to look at the issue more broadly: data centers support many modern services (streaming video is a straightforward example), and ethical responses can include **requiring accountability and disclosure**, **working toward efficiency**, and **making responsible procurement choices**, not only individual abstention. When I discuss these matters with students and others with environmental concerns, I seek to respect the underlying values while also challenging everyone to think rigorously about which actions actually reduce harm.
